{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XTOfd25qRhUN"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, ImageFilter, ImageEnhance\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzipping the image dataset\n",
        "zip_ref = zipfile.ZipFile('original.zip', 'r')\n",
        "zip_ref.extractall('dataset')  # Extracting to the 'dataset' folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "XpV6PelcRog_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BW\n",
        "datagen = ImageDataGenerator()\n",
        "\n",
        "bw_dir = 'dataset/BW'\n",
        "if not os.path.exists(bw_dir):\n",
        "    os.makedirs(bw_dir)\n",
        "\n",
        "original_dir = 'dataset/original'\n",
        "total_images = 20\n",
        "\n",
        "for i in range(1, total_images + 1):\n",
        "    img_path = f'{original_dir}/{i:02d}.jpg'\n",
        "    img = load_img(img_path, color_mode='grayscale')\n",
        "    x = img_to_array(img)\n",
        "    x = x.reshape((1,) + x.shape)\n",
        "\n",
        "    j = 0\n",
        "    for batch in datagen.flow(x, batch_size=1, save_to_dir=bw_dir, save_prefix='bw', save_format='jpeg'):\n",
        "        j += 1\n",
        "        if j >= 10:\n",
        "            break"
      ],
      "metadata": {
        "id": "W_SvUMPN51jQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data paths\n",
        "original_dir = 'dataset/original'\n",
        "BW_dir = 'dataset/BW'\n",
        "train_dir = 'dataset/train'\n",
        "validation_dir = 'dataset/validation'\n",
        "\n",
        "# Create directories for training and validation\n",
        "for category in ['original', 'BW']:\n",
        "    os.makedirs(os.path.join(train_dir, category), exist_ok=True)\n",
        "    os.makedirs(os.path.join(validation_dir, category), exist_ok=True)\n",
        "\n",
        "# Function to split data and move files\n",
        "def split_data(source_folder, train_folder, validation_folder, validation_split=0.2):\n",
        "    files = os.listdir(source_folder)\n",
        "    train_files, validation_files = train_test_split(files, test_size=validation_split)\n",
        "\n",
        "    # Copy files to training directory\n",
        "    for file in train_files:\n",
        "        shutil.copy(os.path.join(source_folder, file), os.path.join(train_folder, file))\n",
        "\n",
        "    # Copy files to validation directory\n",
        "    for file in validation_files:\n",
        "        shutil.copy(os.path.join(source_folder, file), os.path.join(validation_folder, file))\n",
        "\n",
        "# Apply function to original and distorted datasets\n",
        "split_data(original_dir, os.path.join(train_dir, 'original'), os.path.join(validation_dir, 'original'))\n",
        "split_data(BW_dir, os.path.join(train_dir, 'BW'), os.path.join(validation_dir, 'BW'))"
      ],
      "metadata": {
        "id": "bpp58suPWHqf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'dataset/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=5,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    'dataset/validation',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=5,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "WzuNzydszKNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc1135d-54f2-490c-b219-c8f8ba117df9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 174 images belonging to 2 classes.\n",
            "Found 44 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = 'dataset'\n",
        "print(\"Directories in dataset:\", os.listdir(dataset_dir))\n",
        "\n",
        "for category in os.listdir(dataset_dir):\n",
        "    category_path = os.path.join(dataset_dir, category)\n",
        "    if os.path.isdir(category_path):\n",
        "        print(f\"Contents of {category}:\", os.listdir(category_path))"
      ],
      "metadata": {
        "id": "HxEBqGZ6zMrg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "452b61c7-a401-4c12-9989-2993425b7d4e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directories in dataset: ['BW', 'original', 'validation', 'train']\n",
            "Contents of BW: ['bw_0_5846.jpeg', 'bw_0_2795.jpeg', 'bw_0_7569.jpeg', 'bw_0_7401.jpeg', 'bw_0_9843.jpeg', 'bw_0_7188.jpeg', 'bw_0_3232.jpeg', 'bw_0_1602.jpeg', 'bw_0_6902.jpeg', 'bw_0_5316.jpeg', 'bw_0_9990.jpeg', 'bw_0_1616.jpeg', 'bw_0_5309.jpeg', 'bw_0_238.jpeg', 'bw_0_3036.jpeg', 'bw_0_472.jpeg', 'bw_0_8709.jpeg', 'bw_0_6186.jpeg', 'bw_0_5067.jpeg', 'bw_0_9448.jpeg', 'bw_0_8915.jpeg', 'bw_0_331.jpeg', 'bw_0_9090.jpeg', 'bw_0_8871.jpeg', 'bw_0_8245.jpeg', 'bw_0_6728.jpeg', 'bw_0_8495.jpeg', 'bw_0_2005.jpeg', 'bw_0_1794.jpeg', 'bw_0_8977.jpeg', 'bw_0_7063.jpeg', 'bw_0_4135.jpeg', 'bw_0_3663.jpeg', 'bw_0_3492.jpeg', 'bw_0_8094.jpeg', 'bw_0_4566.jpeg', 'bw_0_8677.jpeg', 'bw_0_9537.jpeg', 'bw_0_2590.jpeg', 'bw_0_3206.jpeg', 'bw_0_3545.jpeg', 'bw_0_1469.jpeg', 'bw_0_890.jpeg', 'bw_0_7475.jpeg', 'bw_0_6781.jpeg', 'bw_0_7257.jpeg', 'bw_0_7592.jpeg', 'bw_0_3254.jpeg', 'bw_0_5353.jpeg', 'bw_0_2884.jpeg', 'bw_0_4678.jpeg', 'bw_0_5832.jpeg', 'bw_0_5726.jpeg', 'bw_0_9603.jpeg', 'bw_0_2652.jpeg', 'bw_0_3227.jpeg', 'bw_0_819.jpeg', 'bw_0_1056.jpeg', 'bw_0_3835.jpeg', 'bw_0_2136.jpeg', 'bw_0_3269.jpeg', 'bw_0_165.jpeg', 'bw_0_3031.jpeg', 'bw_0_6023.jpeg', 'bw_0_9978.jpeg', 'bw_0_8893.jpeg', 'bw_0_1413.jpeg', 'bw_0_8508.jpeg', 'bw_0_6599.jpeg', 'bw_0_2461.jpeg', 'bw_0_295.jpeg', 'bw_0_3611.jpeg', 'bw_0_8889.jpeg', 'bw_0_6223.jpeg', 'bw_0_3808.jpeg', 'bw_0_1620.jpeg', 'bw_0_2944.jpeg', 'bw_0_5876.jpeg', 'bw_0_7276.jpeg', 'bw_0_9494.jpeg', 'bw_0_9983.jpeg', 'bw_0_8172.jpeg', 'bw_0_6510.jpeg', 'bw_0_6493.jpeg', 'bw_0_3362.jpeg', 'bw_0_2432.jpeg', 'bw_0_8656.jpeg', 'bw_0_9960.jpeg', 'bw_0_7835.jpeg', 'bw_0_2580.jpeg', 'bw_0_4010.jpeg', 'bw_0_7553.jpeg', 'bw_0_2280.jpeg', 'bw_0_467.jpeg', 'bw_0_6796.jpeg', 'bw_0_7313.jpeg', 'bw_0_8994.jpeg', 'bw_0_4708.jpeg', 'bw_0_9299.jpeg', 'bw_0_4908.jpeg', 'bw_0_7701.jpeg', 'bw_0_6116.jpeg', 'bw_0_4940.jpeg', 'bw_0_6086.jpeg', 'bw_0_5350.jpeg', 'bw_0_2379.jpeg', 'bw_0_6299.jpeg', 'bw_0_1522.jpeg', 'bw_0_6563.jpeg', 'bw_0_8504.jpeg', 'bw_0_2966.jpeg', 'bw_0_6335.jpeg', 'bw_0_9061.jpeg', 'bw_0_4611.jpeg', 'bw_0_508.jpeg', 'bw_0_9630.jpeg', 'bw_0_6639.jpeg', 'bw_0_3915.jpeg', 'bw_0_7850.jpeg', 'bw_0_303.jpeg', 'bw_0_5686.jpeg', 'bw_0_506.jpeg', 'bw_0_8055.jpeg', 'bw_0_5731.jpeg', 'bw_0_7232.jpeg', 'bw_0_6750.jpeg', 'bw_0_8690.jpeg', 'bw_0_5159.jpeg', 'bw_0_2230.jpeg', 'bw_0_7026.jpeg', 'bw_0_4413.jpeg', 'bw_0_8171.jpeg', 'bw_0_6471.jpeg', 'bw_0_3075.jpeg', 'bw_0_2801.jpeg', 'bw_0_8900.jpeg', 'bw_0_2298.jpeg', 'bw_0_2738.jpeg', 'bw_0_9154.jpeg', 'bw_0_5736.jpeg', 'bw_0_8724.jpeg', 'bw_0_2207.jpeg', 'bw_0_8394.jpeg', 'bw_0_601.jpeg', 'bw_0_5813.jpeg', 'bw_0_2986.jpeg', 'bw_0_907.jpeg', 'bw_0_7533.jpeg', 'bw_0_6572.jpeg', 'bw_0_1351.jpeg', 'bw_0_5441.jpeg', 'bw_0_7047.jpeg', 'bw_0_4553.jpeg', 'bw_0_6703.jpeg', 'bw_0_1533.jpeg', 'bw_0_5430.jpeg', 'bw_0_9224.jpeg', 'bw_0_6512.jpeg', 'bw_0_53.jpeg', 'bw_0_4709.jpeg', 'bw_0_8799.jpeg', 'bw_0_9071.jpeg', 'bw_0_9212.jpeg', 'bw_0_2288.jpeg', 'bw_0_2120.jpeg', 'bw_0_8730.jpeg', 'bw_0_4507.jpeg', 'bw_0_8316.jpeg', 'bw_0_2358.jpeg', 'bw_0_4315.jpeg', 'bw_0_315.jpeg', 'bw_0_9474.jpeg', 'bw_0_9162.jpeg', 'bw_0_8544.jpeg', 'bw_0_8400.jpeg', 'bw_0_4393.jpeg', 'bw_0_6526.jpeg', 'bw_0_3975.jpeg', 'bw_0_7068.jpeg', 'bw_0_6753.jpeg', 'bw_0_5200.jpeg', 'bw_0_8330.jpeg', 'bw_0_6937.jpeg', 'bw_0_2000.jpeg', 'bw_0_2887.jpeg', 'bw_0_9812.jpeg', 'bw_0_9415.jpeg', 'bw_0_4965.jpeg', 'bw_0_1851.jpeg', 'bw_0_2951.jpeg', 'bw_0_9551.jpeg', 'bw_0_3996.jpeg', 'bw_0_829.jpeg', 'bw_0_9250.jpeg', 'bw_0_475.jpeg', 'bw_0_2651.jpeg', 'bw_0_3664.jpeg', 'bw_0_9239.jpeg']\n",
            "Contents of original: ['20.jpg', '13.jpg', '06.jpg', '01.jpg', '03.jpg', '18.jpg', '04.jpg', '15.jpg', '16.jpg', '07.jpg', '11.jpg', '09.jpg', '14.jpg', '02.jpg', '19.jpg', '10.jpg', '12.jpg', '08.jpg', '05.jpg', '17.jpg']\n",
            "Contents of validation: ['BW', 'original']\n",
            "Contents of train: ['BW', 'original']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "directories_to_remove = ['original', 'BW']\n",
        "base_dir = 'dataset'\n",
        "\n",
        "for dir_name in directories_to_remove:\n",
        "    dir_path = os.path.join(base_dir, dir_name)\n",
        "    if os.path.exists(dir_path):\n",
        "        shutil.rmtree(dir_path)\n",
        "        print(f\"Removed directory: {dir_path}\")\n",
        "    else:\n",
        "        print(f\"Directory does not exist, no need to remove: {dir_path}\")\n",
        "\n",
        "print(\"Updated contents of the dataset directory:\", os.listdir(base_dir))"
      ],
      "metadata": {
        "id": "x5a3EylHzOHG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a8641ee-9556-41fc-d57b-f1702397b338"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed directory: dataset/original\n",
            "Removed directory: dataset/BW\n",
            "Updated contents of the dataset directory: ['validation', 'train']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "def remove_unwanted_dirs(directory):\n",
        "    checkpoint_dir = os.path.join(directory, '.ipynb_checkpoints')\n",
        "    if os.path.exists(checkpoint_dir):\n",
        "        shutil.rmtree(checkpoint_dir)\n",
        "        print(f\"Removed {checkpoint_dir}\")\n",
        "\n",
        "remove_unwanted_dirs(train_dir)\n",
        "remove_unwanted_dirs(validation_dir)\n",
        "\n",
        "print(\"Updated training directories:\", os.listdir(train_dir))\n",
        "print(\"Updated validation directories:\", os.listdir(validation_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOK1id864rbg",
        "outputId": "2d46fd3e-1df0-47c4-b5e7-e53400eb5926"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated training directories: ['BW', 'original']\n",
            "Updated validation directories: ['BW', 'original']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "# Load the pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)  # L2\n",
        "x = Dropout(0.5)(x)  # Dropout\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "optimizer = tfa.optimizers.AdamW(learning_rate=0.0001, weight_decay=0.001)\n",
        "\n",
        "# Compile the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Prepare training data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    validation_split=0.2  # Use 20% of the data as validation set\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'dataset',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=5,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    'dataset',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=5,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Use early stopping to avoid overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)"
      ],
      "metadata": {
        "id": "9HWck-lczPvc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f401966-7662-4325-bb11-829c94d6461b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/611.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/611.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (24.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.23.0 typeguard-2.13.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Found 176 images belonging to 2 classes.\n",
            "Found 42 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=15,\n",
        "    epochs=10,\n",
        "    callbacks=[early_stopping],\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=5\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "results = model.evaluate(validation_generator)\n",
        "print(\"Test loss, Test accuracy:\", results)"
      ],
      "metadata": {
        "id": "PlNR34wMzTVE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "871d87f7-5469-4cc4-e08e-95f1dd5fb234"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - 84s 5s/step - loss: 7.9526 - accuracy: 0.6400 - val_loss: 8.5033 - val_accuracy: 0.8000\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 70s 5s/step - loss: 10.3472 - accuracy: 0.6667 - val_loss: 11.9309 - val_accuracy: 0.8000\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 70s 5s/step - loss: 11.9537 - accuracy: 0.7333 - val_loss: 13.7020 - val_accuracy: 0.7200\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 66s 4s/step - loss: 9.1250 - accuracy: 0.5867 - val_loss: 13.8132 - val_accuracy: 0.6800\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 69s 5s/step - loss: 4.5765 - accuracy: 0.8169 - val_loss: 5.3265 - val_accuracy: 0.6800\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 67s 5s/step - loss: 6.6657 - accuracy: 0.6761 - val_loss: 8.3294 - val_accuracy: 0.6400\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 70s 5s/step - loss: 4.4667 - accuracy: 0.6479 - val_loss: 8.2524 - val_accuracy: 0.7200\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 67s 5s/step - loss: 8.5315 - accuracy: 0.7333 - val_loss: 6.0176 - val_accuracy: 0.8000\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 71s 5s/step - loss: 5.1080 - accuracy: 0.8000 - val_loss: 5.6223 - val_accuracy: 0.6400\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 68s 4s/step - loss: 5.3362 - accuracy: 0.6933 - val_loss: 6.4291 - val_accuracy: 0.7600\n",
            "9/9 [==============================] - 28s 3s/step - loss: 5.3547 - accuracy: 0.7619\n",
            "Test loss, Test accuracy: [5.354691028594971, 0.761904776096344]\n"
          ]
        }
      ]
    }
  ]
}